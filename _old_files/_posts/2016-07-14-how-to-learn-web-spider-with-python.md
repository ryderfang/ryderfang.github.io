---
layout: post
title: 如何学习 Python 爬虫 | Python Spider Tutorial
categories: [Python, Tutorial]
---

* 转载自知乎专栏[**学习编程**](https://zhuanlan.zhihu.com/passer)
* 感谢作者[__路人甲__](https://www.zhihu.com/people/sgai)的整理

***

## 如何学习python爬虫[入门篇]？

想写这么一篇文章，但是知乎社区爬虫大神很多，光是整理他们的答案就够我这篇文章的内容了。对于我个人来说我更喜欢那种非常实用的教程，这种教程对于想直接上手爬虫做一些小东西的朋友来说是极好的。

用一个精彩的回答作为开头：[如何入门 python 爬虫？ - 谢科的回答](https://www.zhihu.com/question/20899988/answer/24923424)

如果你想学习编程，但是找不到学习路径和资源，欢迎关注专栏：[学习编程](https://zhuanlan.zhihu.com/passer)

<!-- more -->

### python爬虫学习教程

* 来自博客：http://cuiqingcai.com/1052.html

一、爬虫入门

 1. [python爬虫入门一之综述](http://cuiqingcai.com/927.html)
 
 2. [python爬虫入门二之爬虫基础了解](http://cuiqingcai.com/942.html)

 3. [python爬虫入门三之urllib库的基本使用](http://cuiqingcai.com/947.html)

 4. [python爬虫入门四之urllib库的高级用法](http://cuiqingcai.com/954.html)

 5. [python爬虫入门五之urlerror异常处理](http://cuiqingcai.com/961.html)

 6. [python爬虫入门六之cookie的使用](http://cuiqingcai.com/968.html)

 7. [python爬虫入门七之正则表达式](http://cuiqingcai.com/977.html)

二、爬虫实战

 1. [python爬虫实战一之爬取糗事百科段子](http://cuiqingcai.com/990.html)

 2. [python爬虫实战二之爬取百度贴吧帖子](http://cuiqingcai.com/993.html)

 3. [python爬虫实战三之实现山东大学无线网络掉线自动重连](http://cuiqingcai.com/2083.html)

 4. [python爬虫实战四之抓取淘宝mm照片](http://cuiqingcai.com/1001.html)

 5. [python爬虫实战五之模拟登录淘宝并获取所有订单](http://cuiqingcai.com/1076.html)

 6. [python爬虫实战六之抓取爱问知识人问题并保存至数据库](http://cuiqingcai.com/1972.html)

 7. [python爬虫实战七之计算大学本学期绩点](http://cuiqingcai.com/997.html)

 8. [python爬虫实战八之利用selenium抓取淘宝匿名旺旺](http://cuiqingcai.com/2852.html)

三、爬虫利器

 1. [python爬虫利器一之requests库的用法](http://cuiqingcai.com/2556.html)

 2. [python爬虫利器二之beautiful soup的用法](http://cuiqingcai.com/1319.html)

 3. [python爬虫利器三之xpath语法与lxml库的用法](http://cuiqingcai.com/2621.html)

 4. [python爬虫利器四之phantomjs的用法](http://cuiqingcai.com/2599.html)

 5. [python爬虫利器五之selenium的用法](http://cuiqingcai.com/2599.html)

 6. [python爬虫利器六之pyquery的用法](http://cuiqingcai.com/2636.html)

四、爬虫进阶

 1. [python爬虫进阶一之爬虫框架概述](http://cuiqingcai.com/2433.html)

 1. [python爬虫进阶二之pyspider框架安装配置](http://cuiqingcai.com/2443.html)

 1. [python爬虫进阶三之爬虫框架scrapy安装配置](http://cuiqingcai.com/912.html)

 1. [python爬虫进阶四之pyspider的用法](http://cuiqingcai.com/2652.html)

- - - 

### python爬虫入门教程

* 来自CSDN专栏：http://blog.csdn.net/column/details/why-bug.html

 1. [python]网络爬虫（一）：[抓取网页的含义和url基本构成](http://blog.csdn.net/pleasecallmewhy/article/details/8922826)

 1. [Python]网络爬虫（二）：[利用urllib2通过指定的URL抓取网页内容](http://blog.csdn.net/pleasecallmewhy/article/details/8923067)

 1. [Python]网络爬虫（三）：[异常的处理和HTTP状态码的分类](http://blog.csdn.net/pleasecallmewhy/article/details/8923725)

 1. [Python]网络爬虫（四）：[Opener与Handler的介绍和实例应用](http://blog.csdn.net/pleasecallmewhy/article/details/8924889)

 1. [Python]网络爬虫（五）：[urllib2的使用细节与抓站技巧](http://blog.csdn.net/pleasecallmewhy/article/details/8925978)

 1. [Python]网络爬虫（六）：[一个简单的百度贴吧的小爬虫](http://blog.csdn.net/pleasecallmewhy/article/details/8927832)

 1. [Python]网络爬虫（七）：[Python中的正则表达式教程](http://blog.csdn.net/pleasecallmewhy/article/details/8929576)

 1. [Python]网络爬虫（八）：[糗事百科的网络爬虫（v0.3）源码及解析(简化更新)](http://blog.csdn.net/pleasecallmewhy/article/details/8932310)

 1. [Python]网络爬虫（九）：[百度贴吧的网络爬虫（v0.4）源码及解析](http://blog.csdn.net/pleasecallmewhy/article/details/8934726)

 1. [Python]网络爬虫（十）：[一个爬虫的诞生全过程（以山东大学绩点运算为例）](http://blog.csdn.net/pleasecallmewhy/article/details/9305229)

 1. [Python]网络爬虫（十一）：[亮剑！爬虫框架小抓抓Scrapy闪亮登场！](http://blog.csdn.net/pleasecallmewhy/article/details/19354723)

 1. [Python]网络爬虫（十二）：[爬虫框架Scrapy的第一个爬虫示例入门教程](http://blog.csdn.net/pleasecallmewhy/article/details/19642329)

- - -

### 实战练习

* 来自CSDN博客：http://blog.csdn.net/cwyalpha/

Python爬虫学习记录（0）——[Python 爬虫抓站 记录（虾米，百度，豆瓣，新浪微博）](http://blog.csdn.net/cwyalpha/article/details/48111173)

Python爬虫学习记录（1）——[Xiami全站播放数](http://blog.csdn.net/cwyalpha/article/details/48110727)

Python爬虫学习记录（2）——[LDA处理歌词](http://blog.csdn.net/cwyalpha/article/details/48110863)

[百度音乐带标签，作曲，演唱者，类别的歌词数据](http://www.datatang.com/data/43972)

Python爬虫学习记录（4）——[传说中的足彩倍投法。。好像也不是那么靠谱](http://blog.csdn.net/cwyalpha/article/details/48111041)

[2011~2013.5全球所有足球比赛比分数据以及足彩各公司盘口](http://www.datatang.com/data/44171)

Python爬虫学习记录（3）——[用Python获取虾米加心歌曲，并获取MP3下载地址](http://blog.csdn.net/cwyalpha/article/details/48110941)

Python爬虫学习记录（5）——[python mongodb + 爬虫 + web.py 的acfun视频排行榜](http://blog.csdn.net/cwyalpha/article/details/48111101)

* 来自博客：http://aljun.me/

[爬虫教程（1）基础入门](http://aljun.me/post/17)

[爬虫教程（2）性能进阶](http://aljun.me/post/18)

[知乎用户信息爬虫（规模化爬取）](http://aljun.me/post/22)

[用scrapy爬取豆瓣电影新片榜](http://aljun.me/post/4)

[用scrapy对豆瓣top250页面爬取（多页面爬取）](http://aljun.me/post/5)

[用scrapy自动爬取下载图片](http://aljun.me/post/6)

[用scrapy自动下载石原sama的豆瓣影人图集(727张图片，自动下载）](http://aljun.me/post/7)
